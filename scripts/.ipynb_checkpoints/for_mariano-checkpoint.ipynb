{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1ab8da",
   "metadata": {},
   "source": [
    "Created on 08/23/2021.\n",
    "This script has been modified slightly for ease of use by Mariano and Avigail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b407fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "184f8887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(file):\n",
    "    \"\"\"Lodas the pickle file and returns a pickle object\n",
    "    Args:\n",
    "        file (string): labels pickle from mariano\n",
    "    Returns:\n",
    "        pickle: pickle contents returned\n",
    "    \"\"\"\n",
    "    with open(file, 'rb') as fh:\n",
    "        datum = pickle.load(fh)\n",
    "\n",
    "    return datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a70053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def result_of(elec, rep, prod_or_comp, iternum, lag):\n",
    "#     return results[elec][rep][prod_or_comp][iternum][lag]\n",
    "\n",
    "## to get the correlation for: \n",
    "# electrode elec (subset of range(105)), \n",
    "# repetition rep (0 to 49) \n",
    "# prod (0) or comp (1) \n",
    "# iteration iternum (0 to 19, we have 20 iterations per rep, total 1000)repetitions)\n",
    "# lag (0 to 159)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732c8f42",
   "metadata": {},
   "source": [
    "#### Slight reuse of Mariano's function (more info in the above cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa5fbc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(result_dict, electrode_idx, idx_str, perm_range):\n",
    "    idx_of = {'prod': 0, 'comp': 1}\n",
    "    results = []\n",
    "    for rep in range(*perm_range):\n",
    "        result_dict[electrode_idx]\n",
    "        results.append(result_dict[electrode_idx][rep][idx_of[idx_str]])\n",
    "    \n",
    "    return np.vstack(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b75a4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_to_electrode_csv(pickle_object, subject_id, shuffle_str, perm_range=None):\n",
    "    subject_str = str(subject_id)\n",
    "    \n",
    "    electrode_pkl_name = '_'.join([subject_str, 'electrode_names.pkl'])\n",
    "    electrode_pkl = load_pickle(electrode_pkl_name)\n",
    "\n",
    "    subject_dir = os.path.join(os.getcwd(), shuffle_str, subject_str)\n",
    "    os.makedirs(subject_dir, exist_ok=True)\n",
    "\n",
    "    for electrode_idx, electrode_name in zip(electrode_pkl['electrode_id'], electrode_pkl['electrode_name']):\n",
    "\n",
    "        if pickle_object.get(electrode_idx, None):\n",
    "            ret_prod = get_results(pickle_object, electrode_idx, 'prod', perm_range) # returns 1000by160 ndarray\n",
    "            ret_comp = get_results(pickle_object, electrode_idx, 'comp', perm_range)\n",
    "        \n",
    "        np.savetxt(os.path.join(subject_dir, f'{electrode_name}_comp.csv'), ret_comp, delimiter=',')\n",
    "        np.savetxt(os.path.join(subject_dir, f'{electrode_name}_prod.csv'), ret_prod, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba62e3da",
   "metadata": {},
   "source": [
    "### Significance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15a8f26e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17993/2205119696.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultitest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mperform_significance_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoshuffle_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msubjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffle_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats import multitest\n",
    "\n",
    "\n",
    "def perform_significance_testing(project_id, shuffle_folder, noshuffle_folder, conv_flag):\n",
    "    subjects = sorted(glob.glob(os.path.join(shuffle_folder, '*')))\n",
    "    \n",
    "    csv_save_path = os.path.dirname(shuffle_folder)\n",
    "\n",
    "    # This is only for podcast where we ignore electrodes on right hemisphere\n",
    "    hemisphere_indicator = load_pickle('podcast_hemisphere_indicator.pkl')\n",
    "\n",
    "    lags = np.arange(-2000, 2000, 25)\n",
    "\n",
    "    pval_dict = dict()\n",
    "    some_list = []\n",
    "    for subject in subjects:\n",
    "        subject_key = os.path.basename(subject)\n",
    "\n",
    "        # Load all csv files in the shuffle folder\n",
    "        shuffle_elec_file_list = sorted(\n",
    "            glob.glob(\n",
    "                os.path.join(\n",
    "                    shuffle_folder,\n",
    "                    os.path.basename(subject), '*' + conv_flag + '.csv')))\n",
    "\n",
    "        # Load all csv files in the noshuffle folder\n",
    "        main_elec_file_list = sorted(\n",
    "            glob.glob(\n",
    "                os.path.join(\n",
    "                    noshuffle_folder,\n",
    "                    os.path.basename(subject), '*' + conv_flag + '.csv')))\n",
    "\n",
    "        if project_id == 'podcast':\n",
    "            curr_key = hemisphere_indicator.get(int(subject_key), None)\n",
    "\n",
    "            if not curr_key:\n",
    "                pass\n",
    "            elif len(curr_key) == 2:\n",
    "                shuffle_elec_file_list = list(\n",
    "                    filter(lambda x: os.path.basename(x).startswith(('L', 'DL')),\n",
    "                           shuffle_elec_file_list))\n",
    "                main_elec_file_list = list(\n",
    "                    filter(lambda x: os.path.basename(x).startswith(('L', 'DL')),\n",
    "                           main_elec_file_list))\n",
    "            elif len(curr_key) == 1 and 'RH' in curr_key:\n",
    "                continue\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        a = [os.path.basename(item) for item in shuffle_elec_file_list]\n",
    "        b = [os.path.basename(item) for item in main_elec_file_list]\n",
    "\n",
    "        assert set(a) == set(b), \"Mismatch: Electrode Set\"\n",
    "\n",
    "        for elec_file1, elec_file2 in zip(shuffle_elec_file_list,\n",
    "                                          main_elec_file_list):\n",
    "            elecname1 = os.path.split(os.path.splitext(elec_file1)[0])[1]\n",
    "            elecname2 = os.path.split(os.path.splitext(elec_file2)[0])[1]\n",
    "\n",
    "            assert elecname1 == elecname2, 'Mismatch: Electrode Name'\n",
    "\n",
    "            if elecname1.startswith(('SG', 'ECGEKG', 'EEGSG')):\n",
    "                continue\n",
    "\n",
    "            perm_result = pd.read_csv(elec_file1, header=None).values\n",
    "            rc_result = pd.read_csv(elec_file2, header=None).values\n",
    "            \n",
    "            if perm_result.shape[1] != rc_result.shape[1]:\n",
    "                rc_result = rc_result[0, 1:]\n",
    "                \n",
    "            if perm_result.shape[1] != len(lags):\n",
    "                print('perm is wrong length')\n",
    "            else:\n",
    "                omaxs = np.max(perm_result, axis=1)\n",
    "\n",
    "            s = 1 - (sum(np.max(rc_result) > omaxs) / perm_result.shape[0])\n",
    "            some_list.append((subject_key, elecname1, s))\n",
    "\n",
    "    df = pd.DataFrame(some_list, columns=['subject', 'electrode', 'score'])\n",
    "    thresh = 0.01\n",
    "\n",
    "    df1 = df.copy(deep=True)\n",
    "    flag = np.logical_or(np.isclose(df1.score.values, thresh, atol=1e-6), df1.score.values > thresh)\n",
    "\n",
    "    df1 = df1[flag]\n",
    "    df1['electrode'] = df1['electrode'].str.strip('_' + conv_flag)\n",
    "    df1.to_csv(os.path.join(csv_save_path, 'mariano_glove_pre_fdr_' + conv_flag + '.csv'),\n",
    "              index=False,\n",
    "              columns=['subject', 'electrode'])\n",
    "\n",
    "    _, pcor, _, _ = multitest.multipletests(df.score.values,\n",
    "                                            method='fdr_bh',\n",
    "                                            is_sorted=False)\n",
    "\n",
    "    flag = np.logical_or(np.isclose(pcor, thresh), pcor < thresh)\n",
    "\n",
    "    df = df[flag]\n",
    "    df['electrode'] = df['electrode'].str.strip('_' + conv_flag)\n",
    "    df.to_csv(os.path.join(csv_save_path, 'mariano_glove_post_fdr_' + conv_flag + '.csv'), index=False, columns=['subject', 'electrode'])\n",
    "\n",
    "    # Probably have to write a condition if it is podcast or tfs but can be safely run without issues\n",
    "    if project_id == 'podcast':\n",
    "        filter_hemisphere = []\n",
    "        for row in df.itertuples(index=False):\n",
    "            subject = row.subject\n",
    "            electrode = row.electrode\n",
    "\n",
    "            curr_key = hemisphere_indicator.get(int(subject), None)\n",
    "\n",
    "            if not curr_key:\n",
    "                if int(subject) == 798:\n",
    "                    filter_hemisphere.append((subject, electrode))\n",
    "            elif len(curr_key) == 2:\n",
    "                if electrode.startswith(('L', 'DL')):\n",
    "                    filter_hemisphere.append((subject, electrode))\n",
    "            elif len(curr_key) == 1 and 'RH' in curr_key:\n",
    "                continue\n",
    "            else:\n",
    "                filter_hemisphere.append((subject, electrode))\n",
    "\n",
    "        df2 = pd.DataFrame(filter_hemisphere, columns=['subject', 'electrode'])\n",
    "        df2.to_csv(os.path.join(csv_save_path, 'mariano_glove_post_fdr_lhp_' + conv_flag + '.csv'),\n",
    "                   index=False,\n",
    "                   columns=['subject', 'electrode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2a8aa3",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58cc9653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "plt.rcParams.update({\"text.usetex\": False})\n",
    "\n",
    "\n",
    "def plot_results(shuffle_folder, noshuffle_folder, conv_flag):\n",
    "    \n",
    "    pdf_save_path = os.path.dirname(shuffle_folder)\n",
    "    \n",
    "    subjects = sorted(glob.glob(os.path.join(shuffle_folder, '*')))\n",
    "    lags = np.arange(-2000, 2000, 25)\n",
    "\n",
    "    pval_dict = dict()\n",
    "    some_list = []\n",
    "    for subject in subjects:\n",
    "        subject_key = os.path.basename(subject)\n",
    "\n",
    "        shuffle_elec_file_list = sorted(\n",
    "            glob.glob(\n",
    "                os.path.join(\n",
    "                    shuffle_folder,\n",
    "                    os.path.basename(subject), '*' + conv_flag + '.csv')))\n",
    "\n",
    "        main_elec_file_list = sorted(\n",
    "            glob.glob(\n",
    "                os.path.join(\n",
    "                    noshuffle_folder,\n",
    "                    os.path.basename(subject), '*' + conv_flag + '.csv')))\n",
    "\n",
    "        a = [os.path.basename(item) for item in shuffle_elec_file_list]\n",
    "        b = [os.path.basename(item) for item in main_elec_file_list]\n",
    "\n",
    "        assert set(a) == set(b), \"Mismatch: Electrode Set\"\n",
    "\n",
    "        pp = PdfPages(os.path.join(pdf_save_path, 'phase_shuffle_' + conv_flag + '.pdf'))\n",
    "\n",
    "        for elec_file1, elec_file2 in zip(shuffle_elec_file_list,\n",
    "                                          main_elec_file_list):\n",
    "            elecname1 = os.path.split(os.path.splitext(elec_file1)[0])[1]\n",
    "            elecname2 = os.path.split(os.path.splitext(elec_file2)[0])[1]\n",
    "\n",
    "            assert elecname1 == elecname2, 'Mismatch: Electrode Name'\n",
    "            \n",
    "            if elecname1.startswith(('SG', 'ECGEKG', 'EEGSG')):\n",
    "                continue\n",
    "\n",
    "            shuffle_elec_data = pd.read_csv(elec_file1, header=None)\n",
    "            main_elec_data = pd.read_csv(elec_file2, header=None)\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "#             for row in shuffle_elec_data.values:\n",
    "#                 ax.plot(lags, row, linewidth=0.005, color='k', linestyle=':')\n",
    "            ax.plot(lags, main_elec_data.values.T, linewidth=2, color='r')\n",
    "\n",
    "            ax.set(xlabel='lag (s)',\n",
    "                   ylabel='correlation',\n",
    "                   title=elecname1)\n",
    "            ax.set_ylim(-0.05, 0.35)\n",
    "            ax.vlines(0, -0.05, 0.50, linestyles='dashed', linewidth=.25)\n",
    "\n",
    "            pp.savefig(fig)\n",
    "#             plt.show()\n",
    "            plt.close()\n",
    "\n",
    "        pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "391a92a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "plt.rcParams.update({\"text.usetex\": False})\n",
    "\n",
    "\n",
    "def plot_results_new(shuffle_folder, noshuffle_folder, conv_flag):\n",
    "    \n",
    "    pdf_save_path = os.path.join(os.path.dirname(shuffle_folder), conv_flag)\n",
    "    os.makedirs(pdf_save_path, exist_ok=True)\n",
    "    \n",
    "    subjects = sorted(glob.glob(os.path.join(shuffle_folder, '*')))\n",
    "    lags = np.arange(-2000, 2000, 25)\n",
    "\n",
    "    pval_dict = dict()\n",
    "    some_list = []\n",
    "    for subject in subjects:\n",
    "        subject_key = os.path.basename(subject)\n",
    "\n",
    "        shuffle_elec_file_list = sorted(\n",
    "            glob.glob(\n",
    "                os.path.join(\n",
    "                    shuffle_folder,\n",
    "                    os.path.basename(subject), '*' + conv_flag + '.csv')))\n",
    "\n",
    "        main_elec_file_list = sorted(\n",
    "            glob.glob(\n",
    "                os.path.join(\n",
    "                    noshuffle_folder,\n",
    "                    os.path.basename(subject), '*' + conv_flag + '.csv')))\n",
    "\n",
    "        a = [os.path.basename(item) for item in shuffle_elec_file_list]\n",
    "        b = [os.path.basename(item) for item in main_elec_file_list]\n",
    "\n",
    "        assert set(a) == set(b), \"Mismatch: Electrode Set\"\n",
    "\n",
    "        for elec_file1, elec_file2 in zip(shuffle_elec_file_list,\n",
    "                                          main_elec_file_list):\n",
    "            elecname1 = os.path.split(os.path.splitext(elec_file1)[0])[1]\n",
    "            elecname2 = os.path.split(os.path.splitext(elec_file2)[0])[1]\n",
    "\n",
    "            assert elecname1 == elecname2, 'Mismatch: Electrode Name'\n",
    "            \n",
    "            if elecname1.startswith(('SG', 'ECGEKG', 'EEGSG')):\n",
    "                continue\n",
    "\n",
    "            shuffle_elec_data = pd.read_csv(elec_file1, header=None)\n",
    "            main_elec_data = pd.read_csv(elec_file2, header=None)\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "#             for row in shuffle_elec_data.values:\n",
    "#                 ax.plot(lags, row, linewidth=0.005, color='k', linestyle=':')\n",
    "            ax.plot(lags, main_elec_data.values[:, :160].T, linewidth=2, color='r')\n",
    "\n",
    "            ax.set(xlabel='lag (s)',\n",
    "                   ylabel='correlation',\n",
    "                   title=elecname1)\n",
    "            ax.set_ylim(-0.05, 0.35)\n",
    "            ax.vlines(0, -0.05, 0.50, linestyles='dashed', linewidth=.25)\n",
    "\n",
    "            plt.savefig(os.path.join(pdf_save_path, elecname1 + '.png'))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6e4d891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625_00000-to-01000\n",
      "676_00000-to-01000\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "676",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-436e2fb451e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# move info from shuffle pickle to csv files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mshuffle_pickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffle_pickle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mpickle_to_electrode_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffle_pickle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 676"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    subjects = [625, 676]\n",
    "    shuffle_pickle = {625: 'results_114_625.pickle',\n",
    "                         676: 'results_114_676.pickle'}\n",
    "    \n",
    "    noshuffle_pickle = {625: 'results_120_625.pickle',\n",
    "                         676: 'results_120_676.pickle'}\n",
    "\n",
    "    perm_ranges = [(0, 500), (0, 50), (50, 100), (100, 150), (150, 200), (200, 250),\n",
    "                   (250, 300), (300, 350), (350, 400), (400, 450), (450, 500),\n",
    "                   (0, 250), (250, 500)]\n",
    "\n",
    "    # Save permutations from each electrode into a csv file\n",
    "    # Note: For the 'noshuffle' case, I manually copied the data from elsewhere\n",
    "    \n",
    "    for subject in subjects:\n",
    "        for idx, perm_range in enumerate(perm_ranges[1:2]):\n",
    "\n",
    "            # Create folder for that combination\n",
    "            combo_folder_name = f'{subject}_{perm_range[0]*20:05d}-to-{perm_range[1]*20:05d}'\n",
    "            print(combo_folder_name)\n",
    "            os.makedirs(combo_folder_name, exist_ok=True)\n",
    "            \n",
    "            # folder where permutations are stored\n",
    "            shuffle_folder = os.path.join(os.getcwd(), combo_folder_name, 'shuffle')\n",
    "            noshuffle_folder = os.path.join(os.getcwd(), combo_folder_name, 'noshuffle') \n",
    "                    \n",
    "            # move info from shuffle pickle to csv files\n",
    "            shuffle_pickle = load_pickle(shuffle_pickle[subject])\n",
    "            pickle_to_electrode_csv(shuffle_pickle, subject, shuffle_folder, perm_range)\n",
    "\n",
    "            # move info from no-shuffle pickle to csv files\n",
    "            # FIXME: I manually copied the files from a different run\n",
    "            try:\n",
    "                noshuffle_pickle = load_pickle(noshuffle_pickle[subject])\n",
    "                pickle_to_electrode_csv(noshuffle_pickle, subject, noshuffle_folder, (0, 1))\n",
    "            except Exception:\n",
    "                print('No shuffle pickle does not exist')\n",
    "#                 # # copy noshuffle data to this subfolder\n",
    "#                 shutil.copytree(os.path.join(os.getcwd(), 'noshuffle', str(subject)), os.path.join(noshuffle_folder, str(subject)))\n",
    "            \n",
    "#             perform_significance_testing('tfs', shuffle_folder, noshuffle_folder, 'prod')\n",
    "#             perform_significance_testing('tfs', shuffle_folder, noshuffle_folder, 'comp')\n",
    "\n",
    "            plot_results(shuffle_folder, noshuffle_folder, 'prod')\n",
    "            plot_results(shuffle_folder, noshuffle_folder, 'comp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de3a90b",
   "metadata": {},
   "source": [
    "#### Plotting average encoding of significant electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dca1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "main_folder = os.getcwd()\n",
    "folder_list = sorted(glob.glob(os.path.join(main_folder, '6*_*-to-*')))\n",
    "\n",
    "lags = np.arange(-2000, 2000, 25)\n",
    "\n",
    "for folder in folder_list:\n",
    "    print(os.path.basename(folder))\n",
    "    subject_id = os.path.basename(folder)[:3]\n",
    "    csv_list = sorted(glob.glob(os.path.join(folder, 'mariano*.csv')))\n",
    "\n",
    "    for f in glob.glob(os.path.join(folder, '*.png')):\n",
    "        os.remove(f)\n",
    "\n",
    "    for csv_file in csv_list:\n",
    "        csv_contents = pd.read_csv(csv_file)\n",
    "        csv_file_name = os.path.basename(csv_file)\n",
    "        csv_file_name = os.path.splitext(csv_file_name)[0]\n",
    "        print(csv_file_name)\n",
    "\n",
    "        conv_flag = csv_file_name.split('_')[-1]\n",
    "\n",
    "        encoding = []\n",
    "        for electrode in csv_contents.electrode:\n",
    "            electrode_path = os.path.join(folder, 'noshuffle', subject_id,\n",
    "                                          electrode)\n",
    "            try:\n",
    "                with open(electrode_path + '_' + conv_flag + '.csv', 'r') as fh:\n",
    "                    my_data = np.genfromtxt(fh,\n",
    "                                        delimiter=',')\n",
    "            except Exception:\n",
    "                with open(electrode_path +  '.csv', 'r') as fh:\n",
    "                    my_data = np.genfromtxt(fh,\n",
    "                                        delimiter=',')\n",
    "\n",
    "            encoding.append(my_data)\n",
    "        encoding = np.vstack(encoding)\n",
    "        mean_encoding = np.mean(encoding, axis=0)\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(lags, mean_encoding[:160], linewidth=1, color='r')\n",
    "\n",
    "        ax.set(xlabel='lag (s)', ylabel='correlation')\n",
    "        ax.set_ylim(-0.05, 0.250)\n",
    "        ax.vlines(0, -0.05, 0.50, linestyles='dashed', linewidth=.25)\n",
    "\n",
    "        plt.savefig(os.path.join(folder, csv_file_name + '.png'))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ef9fc1",
   "metadata": {},
   "source": [
    "#### Plot no-shuffle average encoding for glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56dfa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "main_folder = os.getcwd()\n",
    "folder_list = sorted(glob.glob(os.path.join(main_folder, '6*_*-to-*')))\n",
    "\n",
    "lags = np.arange(-2000, 2000, 25)\n",
    "\n",
    "for folder in folder_list:\n",
    "    print(os.path.basename(folder))\n",
    "    subject_id = os.path.basename(folder)[:3]\n",
    "    \n",
    "    noshuffle_folder = os.path.join(folder, 'noshuffle', subject_id)\n",
    "\n",
    "    prod_elec_list = sorted(glob.glob(os.path.join(noshuffle_folder, '*_prod.csv')))\n",
    "    comp_elec_list = sorted(glob.glob(os.path.join(noshuffle_folder, '*_comp.csv')))\n",
    "        \n",
    "    prod_encoding = []\n",
    "    for csv_file in prod_elec_list:\n",
    "        my_data = np.genfromtxt(csv_file, delimiter=',')\n",
    "        prod_encoding.append(my_data)\n",
    "    prod_encoding = np.vstack(prod_encoding)\n",
    "    mean_prod_encoding = np.mean(prod_encoding, axis=0)\n",
    "\n",
    "    comp_encoding = []\n",
    "    for csv_file in comp_elec_list:\n",
    "        my_data = np.genfromtxt(csv_file, delimiter=',')\n",
    "        comp_encoding.append(my_data)\n",
    "    comp_encoding = np.vstack(comp_encoding)\n",
    "    mean_comp_encoding = np.mean(comp_encoding, axis=0)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(lags, mean_prod_encoding[:160], linewidth=1, color='r', label='Production')\n",
    "    ax.plot(lags, mean_comp_encoding[:160], linewidth=1, color='b', label='Comprehension')\n",
    "    \n",
    "    ax.set(xlabel='lag (s)', ylabel='correlation')\n",
    "    ax.set_ylim(-0.05, 0.250)\n",
    "    ax.vlines(0, -0.05, 0.50, linestyles='dashed', linewidth=.25)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.savefig(os.path.join(folder, 'average_encoding.png'))\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
